{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloading and extraction\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Set the dataset name and download directory\n",
    "dataset = \"veeralakrishna/butterfly-dataset\"\n",
    "download_dir = \"dataset\"\n",
    "\n",
    "# Initialize Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Create the download directory if it does not exist\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "# Download the dataset\n",
    "print(f\"Downloading {dataset} to {download_dir}...\")\n",
    "api.dataset_download_files(dataset, path=download_dir, unzip=True)\n",
    "print(f\"Dataset downloaded and unzipped to {download_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import ButterflyDataset\n",
    "\n",
    "train_dataset, val_dataset = ButterflyDataset.generate_datasets()\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "print(f\"Shape of the first image: {train_dataset[0][0].shape}\")\n",
    "print(f\"Shape of the first segmentation: {train_dataset[0][1].shape}\")\n",
    "print(f\"label of first image: {train_dataset[0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                [-1, 49152]               0\n",
      "            Linear-2                  [-1, 128]       6,291,584\n",
      "              ReLU-3                  [-1, 128]               0\n",
      "           Dropout-4                  [-1, 128]               0\n",
      "            Linear-5                  [-1, 128]          16,512\n",
      "              ReLU-6                  [-1, 128]               0\n",
      "             Block-7                  [-1, 128]               0\n",
      "            Linear-8                  [-1, 128]          16,512\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "            Block-10                  [-1, 128]               0\n",
      "           Linear-11                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 6,325,898\n",
      "Trainable params: 6,325,898\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 24.13\n",
      "Estimated Total Size (MB): 24.70\n",
      "----------------------------------------------------------------\n",
      " the model looks like: MLP(\n",
      "  (mlp_model): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=49152, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "    (4): Block(\n",
      "      (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# view the model\n",
    "from models import MLP\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(MLP(), (3, 128, 128))\n",
    "\n",
    "model = MLP()\n",
    "print(f\" the model looks like: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets for training and validation\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import ButterflyDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define transformations - resize to 128x128 and convert to tensor\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "segmentation_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "image_dir = \"dataset/leedsbutterfly/images\"\n",
    "segmentation_dir = \"dataset/leedsbutterfly/segmentations\"\n",
    "\n",
    "# Dataset is a list of tuples (image, segmentation, class)\n",
    "dataset = ButterflyDataset(\n",
    "    image_dir=image_dir, \n",
    "    segmentation_dir=segmentation_dir, \n",
    "    transform=image_transform, \n",
    "    seg_transform=segmentation_transform\n",
    ")\n",
    "\n",
    "# Calculate lengths for training and validation splits\n",
    "split = 0.8\n",
    "dataset_length = len(dataset)\n",
    "train_length = int(split * dataset_length)\n",
    "val_length = dataset_length - train_length\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_length, val_length])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic verification of the dataset\n",
    "print(f\"Training dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_dataset)}\")\n",
    "\n",
    "for i in range(4):\n",
    "    image, segmentation, label = train_dataset[i]\n",
    "    print(f\"Image shape: {image.shape}, Segmentation shape: {segmentation.shape}, Label: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming train_dataset is your dataset instance\n",
    "labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "# Count unique classes\n",
    "unique_classes = set(labels)\n",
    "print(\"Number of unique classes:\", len(unique_classes))\n",
    "print(\"Unique classes:\", unique_classes)\n",
    "\n",
    "# (Optional) Frequency count\n",
    "class_counts = Counter(labels)\n",
    "print(\"Class frequencies:\", class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few of the images\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i in range(4):\n",
    "    image, segmentation, label = train_dataset[i]\n",
    "    axs[0, i].imshow(image.permute(1, 2, 0))\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[0, i].set_title(f\"Image {i+1}\")\n",
    "\n",
    "    axs[1, i].imshow(segmentation.squeeze()) #, cmap=\"gray\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "    axs[1, i].set_title(f\"Segmentation {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP training for classification\n",
    "# the training occurs in the trainer.py file\n",
    "# call the trainer \n",
    "from trainer import MLPTrainer\n",
    "from models import MLP\n",
    "\n",
    "# Create an instance of the MLP model\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "# For classification, we use cross entropy loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model and perform training\n",
    "\n",
    "for epoch in range(100):\n",
    "    for imgs, labels in train_loader:\n",
    "        pred = model(imgs)\n",
    "\n",
    "        loss_value = loss_fn(pred, labels)\n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    print(f\" epoch: {epoch}\")\n",
    "    print(f\" loss: {loss_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like the model is overfitting with very low loss on training set\n",
    "# Compute accuracy on the validation set\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        pred = model(imgs)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {correct / total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using a different method\n",
    "# check the accuracy\n",
    "validation_images = torch.stack([im for im, _ in val_set], dim=0)\n",
    "validation_label = torch.tensor([label for _, label in val_set])\n",
    "\n",
    "\n",
    "pred_test = model(validation_images.view(-1, 3 * 128 * 128))\n",
    "print(pred_test[:2])  # outputs logits, inputs into softmax\n",
    "\n",
    "# code to compute the accuracy to distinguish between class 0 and 1\n",
    "# boolean check on which predictions are correct, convert to float, take mean\n",
    "print((pred_test.argmax(dim=1) == validation_label).float().mean())\n",
    "\n",
    "\n",
    "# accuraccy is 50%, which is 5 times better than random chance of 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict the class of a few images\n",
    "# Load a few images from the validation set\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "# Predict the classes of the images\n",
    "preds = model(images)\n",
    "predicted_classes = preds.argmax(dim=1)\n",
    "\n",
    "# Display the images and the predicted classes\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12, 12))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = axs[i // 4, i % 4]\n",
    "    ax.imshow(images[i].permute(1, 2, 0))  # Convert [3, 256, 256] to [256, 256, 3]\n",
    "    ax.set_title(f\"Predicted: {predicted_classes[i]}, Actual: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
